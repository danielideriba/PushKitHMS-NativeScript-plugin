"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.stopServer = exports.startServer = void 0;
const tslib_1 = require("tslib");
const devkit_1 = require("@nrwl/devkit");
const app_root_1 = require("@nrwl/tao/src/utils/app-root");
const fs_1 = require("fs");
const net_1 = require("net");
const perf_hooks_1 = require("perf_hooks");
const file_hasher_1 = require("../../../hasher/file-hasher");
const git_hasher_1 = require("../../../hasher/git-hasher");
const project_graph_1 = require("../../project-graph");
const socket_utils_1 = require("../socket-utils");
const watcher_1 = require("./watcher");
/**
 * We have two different use-cases for the "daemon" server:
 * 1) Running in a background process so that the daemon is purely an implementation detail.
 * 2) Running in the main process in order to aid with development/debugging (technically, of course, in this case
 * it isn't actually a daemon server at all, but for simplicity we stick with the same general name as its primary
 * reason for existence is to be run in a background process).
 *
 * For (1) we do not want to log things from the daemon server to stdout/stderr, so we instead write to a file.
 *
 * This file location will be set by the `./exec/index.ts` utilities when starting the server so that we can
 * provide feedback to the user as to its location via stdout on the parent process and still not cause the child
 * process to be "undetachable".
 *
 * For (2) we simply log to stdout.
 */
let _serverLogOutputFile;
function serverLog(...s) {
    /**
     * If _serverLogOutputFile has not be set when starting the server, it means we are
     * running it in the current process and we should log to stdout.
     */
    if (!_serverLogOutputFile) {
        console.log(formatLogMessage(`${s.join(' ')}`));
        return;
    }
    fs_1.appendFileSync(_serverLogOutputFile, formatLogMessage(`${s.join(' ')}\n`));
}
function formatLogMessage(message) {
    return `[NX Daemon Server] - ${new Date().toISOString()} - ${message}`;
}
/**
 * To improve the overall readibility of the logs, we categorize things by "trigger":
 *
 * - [REQUEST] meaning that the current set of actions were triggered by a client request to the server
 * - [WATCHER] meaning the the current set of actions were triggered by handling changes to the workspace files
 *
 * We keep those two "triggers" left aligned at the top level and then indent subsequent logs so that there is a
 * logical hierarchy/grouping.
 */
function requestLog(...s) {
    serverLog(`[REQUEST]: ${s.join(' ')}`);
}
function watcherLog(...s) {
    serverLog(`[WATCHER]: ${s.join(' ')}`);
}
function nestedLog(...s) {
    serverLog(`  ${s.join(' ')}`);
}
/**
 * We cache the latest known HEAD value so that we can potentially skip some initialization work.
 */
let cachedGitHead;
/**
 * We cache the latest copy of the serialized project graph itself in memory so that in the
 * best case scenario we can skip all graph construction and serialization work entirely.
 */
let cachedSerializedProjectGraph;
function createAndSerializeProjectGraph() {
    perf_hooks_1.performance.mark('create-project-graph-start');
    const projectGraph = project_graph_1.createProjectGraph(undefined, undefined, undefined, '4.0');
    perf_hooks_1.performance.mark('create-project-graph-end');
    perf_hooks_1.performance.measure('total execution time for createProjectGraph()', 'create-project-graph-start', 'create-project-graph-end');
    perf_hooks_1.performance.mark('json-stringify-start');
    const serializedProjectGraph = JSON.stringify(projectGraph);
    perf_hooks_1.performance.mark('json-stringify-end');
    perf_hooks_1.performance.measure('serialize graph', 'json-stringify-start', 'json-stringify-end');
    return serializedProjectGraph;
}
/**
 * File watcher subscription.
 */
let watcherSubscription;
/**
 * We need to make sure that we instantiate the PerformanceObserver only once, otherwise
 * we will end up with duplicate entries in the server logs.
 */
let performanceObserver;
const server = net_1.createServer((socket) => {
    if (!performanceObserver) {
        performanceObserver = new perf_hooks_1.PerformanceObserver((list) => {
            const entry = list.getEntries()[0];
            // Slight indentation to improve readability of the overall log file
            nestedLog(`Time taken for '${entry.name}'`, `${entry.duration}ms`);
        });
        performanceObserver.observe({ entryTypes: ['measure'], buffered: false });
    }
    socket.on('data', (data) => {
        /**
         * If anything other than the known project graph creation request payload is sent to
         * the server, we throw an error.
         */
        const payload = data.toString();
        if (payload !== 'REQUEST_PROJECT_GRAPH_PAYLOAD') {
            throw new Error(`Unsupported payload sent to daemon server: ${payload}`);
        }
        perf_hooks_1.performance.mark('server-connection');
        requestLog('Client Request for Project Graph Received');
        const currentGitHead = git_hasher_1.gitRevParseHead(app_root_1.appRootPath);
        let serializedProjectGraph;
        /**
         * Cached HEAD has changed, we must perform full file-hashing initialization work and
         * recompute the project graph
         */
        if (currentGitHead !== cachedGitHead) {
            cachedSerializedProjectGraph = undefined;
            nestedLog(`Cached HEAD does not match current (${currentGitHead}), performing full file hash init and recomputing project graph...`);
            file_hasher_1.defaultFileHasher.init();
            cachedGitHead = currentGitHead;
            serializedProjectGraph = createAndSerializeProjectGraph();
        }
        else {
            /**
             * We know at this point that the cached HEAD has not changed so now there are two possibilities:
             *
             * 1) We have not computed the project graph and cached it for the untracked and uncommitted changes
             * and need to ask git for this information (slower)
             *
             * 2) We already have a cached serialized project graph (which we trust has been kept up to date
             * by the file watching logic) so we can immediately resolve it to the client (faster)
             */
            if (cachedSerializedProjectGraph) {
                nestedLog(`State unchanged since last request, resolving in-memory cached project graph...`);
                serializedProjectGraph = cachedSerializedProjectGraph;
            }
            else {
                // Update the file-hasher's knowledge of the untracked and uncommitted changes in order to recompute the project graph
                file_hasher_1.defaultFileHasher.incrementalUpdate(git_hasher_1.getUntrackedAndUncommittedFileHashes(app_root_1.appRootPath));
                nestedLog(`Unknown untracked/uncommitted file state, recomputing project graph...`);
                serializedProjectGraph = createAndSerializeProjectGraph();
            }
        }
        /**
         * Cache the latest version of the project graph in memory so that we can potentially skip a lot
         * of expensive work on the next client request.
         *
         * For reference, on the very large test repo https://github.com/vsavkin/interstellar the project
         * graph nxdeps.json file is about 32MB, so memory utilization should not be a huge concern.
         */
        cachedSerializedProjectGraph = serializedProjectGraph;
        perf_hooks_1.performance.mark('serialized-project-graph-ready');
        perf_hooks_1.performance.measure('total for creating and serializing project graph', 'server-connection', 'serialized-project-graph-ready');
        socket.write(serializedProjectGraph, () => {
            perf_hooks_1.performance.mark('serialized-project-graph-written-to-client');
            perf_hooks_1.performance.measure('write project graph to socket', 'serialized-project-graph-ready', 'serialized-project-graph-written-to-client');
            /**
             * Close the connection once all data has been written to the socket so that the client
             * knows when to read it.
             */
            socket.end();
            perf_hooks_1.performance.measure('total for server response', 'server-connection', 'serialized-project-graph-written-to-client');
            const bytesWritten = Buffer.byteLength(serializedProjectGraph, 'utf-8');
            nestedLog(`Closed Connection to Client (${bytesWritten} bytes transferred)`);
        });
    });
});
/**
 * Server process termination clean up and logging.
 */
function handleServerProcessTermination() {
    return tslib_1.__awaiter(this, void 0, void 0, function* () {
        server.close();
        /**
         * Tear down any file watchers that may be running.
         */
        if (watcherSubscription) {
            yield watcherSubscription.unsubscribe();
            watcherLog(`Unsubscribed from changes within: ${app_root_1.appRootPath}`);
        }
        serverLog('Server Stopped');
        devkit_1.logger.info('NX Daemon Server - Stopped');
        process.exit(0);
    });
}
process
    .on('SIGINT', handleServerProcessTermination)
    .on('SIGTERM', handleServerProcessTermination)
    .on('SIGHUP', handleServerProcessTermination);
/**
 * When applicable files in the workspaces are changed (created, updated, deleted),
 * we need to recompute the cached serialized project graph so that it is readily
 * available for the next client request to the server.
 */
const handleWorkspaceChanges = (err, changeEvents) => {
    /**
     * We know that something must have happened in the workspace so it makes sense
     * to proactively destroy any previous knowledge of the project graph at this point.
     */
    cachedSerializedProjectGraph = undefined;
    if (err || !changeEvents || !changeEvents.length) {
        watcherLog('Unexpected Error');
        console.error(err);
        return;
    }
    watcherLog(watcher_1.convertChangeEventsToLogMessage(changeEvents));
    /**
     * Update the file-hasher's knowledge of the non-deleted changed files in order to
     * recompute and cache the project graph in memory.
     */
    try {
        const filesToHash = [];
        const deletedFiles = [];
        for (const event of changeEvents) {
            if (event.type === 'delete') {
                deletedFiles.push(event.path);
            }
            else {
                filesToHash.push(event.path);
            }
        }
        perf_hooks_1.performance.mark('hash-watched-changes-start');
        const updatedHashes = git_hasher_1.getGitHashForFiles(filesToHash, app_root_1.appRootPath);
        perf_hooks_1.performance.mark('hash-watched-changes-end');
        perf_hooks_1.performance.measure('hash changed files from watcher', 'hash-watched-changes-start', 'hash-watched-changes-end');
        file_hasher_1.defaultFileHasher.incrementalUpdate(updatedHashes);
        file_hasher_1.defaultFileHasher.removeFiles(deletedFiles);
        nestedLog(`Updated file-hasher based on watched changes, recomputing project graph...`);
        cachedSerializedProjectGraph = createAndSerializeProjectGraph();
    }
    catch (err) {
        serverLog(`Unexpected Error`);
        console.error(err);
    }
};
function startServer({ serverLogOutputFile, }) {
    return tslib_1.__awaiter(this, void 0, void 0, function* () {
        _serverLogOutputFile = serverLogOutputFile;
        // See notes above on OS differences regarding clean up of existings connections.
        if (!socket_utils_1.isWindows) {
            socket_utils_1.killSocketOrPath();
        }
        return new Promise((resolve) => {
            server.listen(socket_utils_1.FULL_OS_SOCKET_PATH, () => tslib_1.__awaiter(this, void 0, void 0, function* () {
                serverLog(`Started listening on: ${socket_utils_1.FULL_OS_SOCKET_PATH}`);
                if (!watcherSubscription) {
                    watcherSubscription = yield watcher_1.subscribeToWorkspaceChanges(handleWorkspaceChanges);
                    watcherLog(`Subscribed to changes within: ${app_root_1.appRootPath}`);
                }
                return resolve(server);
            }));
        });
    });
}
exports.startServer = startServer;
function stopServer() {
    return tslib_1.__awaiter(this, void 0, void 0, function* () {
        return new Promise((resolve, reject) => {
            server.close((err) => {
                if (err) {
                    /**
                     * If the server is running in a detached background process then server.close()
                     * will throw this error even if server is actually alive. We therefore only reject
                     * in case of any other unexpected errors.
                     */
                    if (!err.message.startsWith('Server is not running')) {
                        return reject(err);
                    }
                }
                socket_utils_1.killSocketOrPath();
                /**
                 * The distinction regarding background process or not is not relevant for stopping the server,
                 * always pretty print the message to stdout.
                 */
                devkit_1.logger.info('NX Daemon Server - Stopped');
                return resolve();
            });
        });
    });
}
exports.stopServer = stopServer;
//# sourceMappingURL=server.js.map